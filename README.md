# Projects
**This is a repository of my small pet-projects and I've decided to compile them all together in one table**
**Repository content:**

| âœ…  Name of the project|  ğŸ“ Brief description | ğŸ˜®â€ğŸ’¨ Stack | ğŸ¤– Methods, models |
|--------|--------|--------|--------|
| **Comment moderation** ğŸ”—[Project_Comments](Project_Comments.ipynb)| Online store launches a new service. Now users can edit and supplement product descriptions like in wiki communities. The store needs a tool that will search for toxic comments and send them for moderation. We will train the model to categorize comments into positive and negative. We have at our disposal a dataset with markup on the toxicity of edits. | **`re` `nltk` `spacy` `sklearn` `catboost`** | `Lemmatization` `TfidfVectorizer` `RandomizedSearchCV` `LogisticRegression` |
| **Forecasting taxi orders** ğŸ”—[Project_Used_Cars](Project_Used_Cars.ipynb) | The company has collected historical data on cab orders at airports. In order to attract more drivers during the peak period, we need to predict the number of cab orders for the next hour. Let's build a model for such a prediction. | **`pandas` `sklearn` `statsmodels`** | `Seasonal Decomposition` `RMSE` `RandomForestRegressor` `TimeSeriesSplit` |
| **Determining the price of cars** ğŸ”—[Project_Used_Cars](Project_Used_Cars.ipynb) | A service for selling used cars is developing an app to attract new customers. There you can quickly find out the market value of your car. We have historical data at our disposal: technical characteristics, equipment and prices of cars. We need to build a model to determine the price. | **`lgbm` `catboost` `sklearn`** | `OneHotEncoder` `MEstimateEncoder` `StandardScaler` `CatBoostRegressor` `LGBMRegressor` `GridSearchCV` |
| **Outflow of clients** ğŸ”—[Project_Outflow_Clients](Project_Ouflow_Clients.ipynb) | Clients started leaving a bank every month. Suppose it is cheaper to keep current clients than to attract new ones. We have to predict whether a client will leave the bank in the near future or not. We are provided with historical data on customer behavior and termination of contracts with the bank. Let's build a model with the most large possible value of F1-measure. Data source: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling | **`pandas` `sklearn` `seaborn`** | `roc_auc_score` `f1_score` `Hyperparameters tuning` `Upsampling` `Downsampling` `OHE` |
| **Recommendation of tariffs** ğŸ”—[Project_Tariffs](Project_Tariffs.ipynb) | We have at our disposal data on the behavior of customers who have already migrated to these tariffs. We need to build a model for the classification task that will select the appropriate tariff. Data preprocessing will not be needed - the purpose of the task is to conduct classification process | **`pandas` `seaborn` `sklearn`** | `accuracy` `precision` `recall` `DecisionTreeClassifier` `RandomForestClassifier` `LogisticRegression` |
| **Analysis and prediction of computer games' sales** ğŸ”—[Project_Computer_Games](Project_Computer_Games.ipynb) | We are going to analyze and predict the sales of an online computer game store based on data up to 2016. In the dataset comes the acronym ESRB (Entertainment Software Rating Board), which is an association that determines the age rating of computer games. The ESRB rates game content and assigns it an appropriate age category, such as "For Adults," "For Young Children," or "For Teens." | **`pandas` `numpy` `plotly.graph_objects`**| `Preprocessing` `Testing Hypotheses` |
| **Selecting a location for the oil well** ğŸ”—[Project_Oil_Well](Project_Oil_Well.ipynb) | We are given oil samples from three regions: each has 10,000 fields where we have measured the quality of the oil and the amount of oil reserves. Let's build a machine learning model that will help us identify the region where production will bring the highest profit. We'll analyze the possible profits and risks using Bootstrap techniques. | **`pandas`, `numpy`, `sklearn`** | `Bootstrap` `Scaling` `LinearRegression`| 
