# Projects

**Repository content:**

| ✅  Name of the project|  📝 Brief description | Stack | Methods, models |
|--------|--------|--------|--------|
| **1. Research of advertisements of apartments for sale** 🔗[Project_Advertisements](Project_Advertisements.ipynb)|We have at our disposal data from the Yandex.Real Estate service \\ - an archive of advertisements for apartments for sale in St. Petersburg and neighboring cities for several years. Let's determine the market value of real estate objects. Our task is to set the parameters. This will allow you to build an automated system: it will track anomalies and fraudulent activity. | **`pandas` `matplotlib.pyplot` `numpy`**| `Data Analysis` `Preprocessing` |
| **2. Analysis and prediction of computer games' sales** 🔗[Project_Computer_Games](Project_Computer_Games.ipynb) | We are going to analyze and predict the sales of an online computer game store based on data up to 2016. In the dataset comes the acronym ESRB (Entertainment Software Rating Board), which is an association that determines the age rating of computer games. The ESRB rates game content and assigns it an appropriate age category, such as "For Adults," "For Young Children," or "For Teens." | **`pandas` `numpy` `plotly.graph_objects`**| `Preprocessing` `Testing Hypotheses` |
| **3. Selecting a location for the oil well** 🔗[Project_Oil_Well](Project_Oil_Well.ipynb) | We are given oil samples from three regions: each has 10,000 fields where we have measured the quality of the oil and the amount of oil reserves. Let's build a machine learning model that will help us identify the region where production will bring the highest profit. We'll analyze the possible profits and risks using Bootstrap techniques. | **`pandas`, `numpy`, `sklearn`** | `Bootstrap` `Scaling` `LinearRegression`| 
| **4. Recommendation of tariffs** 🔗[Project_Tariffs](Project_Tariffs.ipynb) | We have at our disposal data on the behavior of customers who have already migrated to these tariffs. We need to build a model for the classification task that will select the appropriate tariff. Data preprocessing will not be needed - the purpose of the task is to conduct classification process | **`pandas` `seaborn` `sklearn`** | `accuracy` `precision` `recall` `DecisionTreeClassifier` `RandomForestClassifier` `LogisticRegression` |
| **5. Outflow of clients** 🔗[Project_Outflow_Clients](Project_Ouflow_Clients.ipynb) | Clients started leaving a bank every month. Suppose it is cheaper to keep current clients than to attract new ones. We have to predict whether a client will leave the bank in the near future or not. We are provided with historical data on customer behavior and termination of contracts with the bank. Let's build a model with the most large possible value of F1-measure. Data source: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling | **`pandas` `sklearn` `seaborn`** | `roc_auc_score` `f1_score` `Hyperparameters tuning` `Upsampling` `Downsampling` `OHE` |
| **6. Determining the price of cars** 🔗[Project_Used_Cars](Project_Used_Cars.ipynb) | A service for selling used cars is developing an app to attract new customers. There you can quickly find out the market value of your car. We have historical data at our disposal: technical characteristics, equipment and prices of cars. We need to build a model to determine the price. | **`lgbm` `catboost` `sklearn`** | `OneHotEncoder` `MEstimateEncoder` `StandardScaler` `CatBoostRegressor` `LGBMRegressor` `GridSearchCV` |
| **7. Forecasting taxi orders** 🔗[Project_Used_Cars](Project_Used_Cars.ipynb) | The company has collected historical data on cab orders at airports. In order to attract more drivers during the peak period, we need to predict the number of cab orders for the next hour. Let's build a model for such a prediction. | **`pandas` `sklearn` `statsmodels`** | `Seasonal Decomposition` `RMSE` `RandomForestRegressor` `TimeSeriesSplit` |
| **8. Comment moderation** | Online store launches a new service. Now users can edit and supplement product descriptions like in wiki communities. The store needs a tool that will search for toxic comments and send them for moderation. We will train the model to categorize comments into positive and negative. We have at our disposal a dataset with markup on the toxicity of edits. | **`re` `nltk` `spacy` `sklearn` `catboost`** | `Lemmatization` `TfidfVectorizer` `RandomizedSearchCV` `LogisticRegression` |
|   |  ๑(◕‿◕)๑  |
|  Week 9.  James Stein paradox|   Class 9: Covariances|
|   | 🔗 Notebook >>>   |
|  Week 10.  L1, L2 regularization|   Class 10: Regularizations|
|   | 🔗 Notebook >>>   |
|  Week 11.  Log regressions |   Class 11: Log regressions|
|   | 🔗 Notebook >>>   |
|  Week 12.  Clustering |   Class 12: Clustering|
|   | 🔗 Notebook >>>   |
|  Week 13.  ETS |   Class 13: Time series, ETS|
|   | 🔗 Notebook >>>   |
|  Week 14.  Bayesian approach |   Class 14: Time series forecasting|
|   | 🔗 Notebook >>>   |
|  Week 15.  MCMC, DLT |   Class 15: DLT|
|   | 🔗 Notebook >>>   |
