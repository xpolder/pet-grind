# Projects

**Repository content:**

| âœ…  Name of the project|  ðŸ“ Brief description | Stack | Methods, models |
|--------|--------|--------|--------|
| **1. Research of advertisements of apartments for sale** ðŸ”—[Project_Advertisements](Project_Advertisements.ipynb)|We have at our disposal data from the Yandex.Real Estate service \\ - an archive of advertisements for apartments for sale in St. Petersburg and neighboring cities for several years. Let's determine the market value of real estate objects. Our task is to set the parameters. This will allow you to build an automated system: it will track anomalies and fraudulent activity. | **`pandas` `matplotlib.pyplot` `numpy`**| `Data Analysis` `Preprocessing` |
| **2. Analysis and prediction of computer games' sales** ðŸ”—[Project_Computer_Games](Project_Computer_Games.ipynb) | We are going to analyze and predict the sales of an online computer game store based on data up to 2016. In the dataset comes the acronym ESRB (Entertainment Software Rating Board), which is an association that determines the age rating of computer games. The ESRB rates game content and assigns it an appropriate age category, such as "For Adults," "For Young Children," or "For Teens." | **`pandas` `numpy` `plotly.graph_objects`**| `Preprocessing` `Testing Hypotheses` |
| **3. Selecting a location for the oil well** ðŸ”—[Project_Oil_Well](Project_Oil_Well.ipynb) | We are given oil samples from three regions: each has 10,000 fields where we have measured the quality of the oil and the amount of oil reserves. Let's build a machine learning model that will help us identify the region where production will bring the highest profit. We'll analyze the possible profits and risks using Bootstrap techniques. | **`pandas`, `numpy`, `sklearn`** | `Bootstrap` `Scaling` `LinearRegression`| 
| **4. Recommendation of tariffs** ðŸ”—[Project_Tariffs](Project_Tariffs.ipynb) | We have at our disposal data on the behavior of customers who have already migrated to these tariffs. We need to build a model for the classification task that will select the appropriate tariff. Data preprocessing will not be needed - the purpose of the task is to conduct classification process | **`pandas` `seaborn` `sklearn`** | `accuracy` `precision` `recall` `DecisionTreeClassifier` `RandomForestClassifier` `LogisticRegression` |
| **5. Outflow of clients** ðŸ”—[Project_Outflow_Clients](Project_Ouflow_Clients.ipynb) | Clients started leaving a bank every month. Suppose it is cheaper to keep current clients than to attract new ones. We have to predict whether a client will leave the bank in the near future or not. We are provided with historical data on customer behavior and termination of contracts with the bank. Let's build a model with the most large possible value of F1-measure. Data source: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling | **`pandas` `sklearn` `seaborn`** | `roc_auc_score` `f1_score` `Hyperparameters tuning` `Upsampling` `Downsampling` `OHE` |
| **6. Determining the price of cars** | Ð¡ÐµÑ€Ð²Ð¸Ñ Ð¿Ð¾ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»ÐµÐ¹ Ñ Ð¿Ñ€Ð¾Ð±ÐµÐ³Ð¾Ð¼ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ñ€Ð¸Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð½Ð¾Ð²Ñ‹Ñ… ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð². Ð’ Ð½Ñ‘Ð¼ Ð¼Ð¾Ð¶Ð½Ð¾ Ð±Ñ‹ÑÑ‚Ñ€Ð¾ ÑƒÐ·Ð½Ð°Ñ‚ÑŒ Ñ€Ñ‹Ð½Ð¾Ñ‡Ð½ÑƒÑŽ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ ÑÐ²Ð¾ÐµÐ³Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»Ñ. Ð’ Ð½Ð°ÑˆÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ñ€ÑÐ¶ÐµÐ½Ð¸Ð¸ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ: Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸, ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚Ð°Ñ†Ð¸Ð¸ Ð¸ Ñ†ÐµÐ½Ñ‹ Ð°Ð²Ñ‚Ð¾Ð¼Ð¾Ð±Ð¸Ð»ÐµÐ¹. ÐÐ°Ð¼ Ð½ÑƒÐ¶Ð½Ð¾ Ð¿Ð¾ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚Ð¸. | **`lgbm` `catboost` `sklearn`** | `OneHotEncoder` `MEstimateEncoder` `StandardScaler` `CatBoostRegressor` `LGBMRegressor` `GridSearchCV` |
|   |   ðŸ”— Notebook >>> |
|  Week 7.  Matrices in regression |   Class 7: Matrices|
|   | à¹‘(â—•â€¿â—•)à¹‘    |
|  Week 8.  SVD/PCA|   Class 8: Covariances|
|   |  à¹‘(â—•â€¿â—•)à¹‘  |
|  Week 9.  James Stein paradox|   Class 9: Covariances|
|   | ðŸ”— Notebook >>>   |
|  Week 10.  L1, L2 regularization|   Class 10: Regularizations|
|   | ðŸ”— Notebook >>>   |
|  Week 11.  Log regressions |   Class 11: Log regressions|
|   | ðŸ”— Notebook >>>   |
|  Week 12.  Clustering |   Class 12: Clustering|
|   | ðŸ”— Notebook >>>   |
|  Week 13.  ETS |   Class 13: Time series, ETS|
|   | ðŸ”— Notebook >>>   |
|  Week 14.  Bayesian approach |   Class 14: Time series forecasting|
|   | ðŸ”— Notebook >>>   |
|  Week 15.  MCMC, DLT |   Class 15: DLT|
|   | ðŸ”— Notebook >>>   |
